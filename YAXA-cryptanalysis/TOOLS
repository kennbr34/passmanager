These are tools I used for cryptanalysis of the YAXA cipher.

yaxafileutil.c - Is a sipmle file-to-file encryption/decryption utility.  This can produce larger files to test than passmanager.
It also made it easier to examine the keystream generated, as encrypting a file full of zeroes will reveal it.

pxorc.c - XORs plain-text against cipher-text to produce the keystream that the cipher-text was encrypted with. This can be used
to extract the keystream from files not created by encrypting a zero file.

stripsalt.c - Simply strips off the specified preceding bytes, so that we are not applying pxorc against any salt or tax bytes.

freqan.c - Generates a frequency table of characters contained in the file, breaking down their percentage and total raw number.

periodsearch.c - Recursively searches the file for the beginning of a running key by searching for a specifed number of bytes. If the first
sequence of bytes n-bytes long is not found, then the second byte sequence n-bytes long is searched for, until all byte sequences n-bytes long
have been searched (helpful in skipping over the salt).  If the byte-sequence is found in the file, this indicates the beginning of the key 
becoming peridic, and the program will print the size of the period and where in the file it begins. If no byte sequences n-bytes long are 
found, the key is non-periodic. The byte sequence should be at least 4 bytes long to avoid matching false-positives.

makedummydatabase.sh - Generates a mock entry file the same that passmanager would make in plain-text with pseudeo-random padding.
This way it can be generated to be of any filesize, without waiting for passmanager to generate that size of database.  Once the mock
database is created, yaxafileutil can be used to encrypt it.  Needs mkpasswd.c compiled.

keystreamextractor.sh - A script to demonstrate how to extract a keystream

Statistical Testing

dihardertest.sh - Runs a statistical analysis on cipher-text created from a mock database file. A file of the same size is generated
from urandom to compare against.  freqan is ran against them to show even distribution, and then dieharder runs NIST STS tests 
against both the cipher-text and urandom bytes to see if cipher-text is indistinguishable from randomness.

This will create a mock database, and automatically run tests against it:
./makedummydatabase.sh 128 && ./dihardtest.sh 128 > ./randomtest.log

Previous tests have been run and their results saved in two directories:

3M_filesize_testresults
128M_filesize_testresults

Dieharder fails even urandom bytes if not of excessive size, so first I test only 3 MB of yaxa data against urandomness
to compare dieharder's results against each, and then do 128MB of data from each to give dieharder enough data not to fail.
The point isn't really to make dieharder PASS or FAIL, but to see if there's a distinguishable pattern between how often
urandom bytes and the cipher-text bytes FAIL/PASS each test.  As long as they're not failing the same tests, the cipher-text
and urandom bytes are indistinguishable from each other.

./keystreamtesting.sh - Was used to run dieharder and freqan against the keystream derived.
./keystreamtesting.sh 1 will run a comparitive test against /dev/urandom bytes and store the output in keystreamtesting1.log
